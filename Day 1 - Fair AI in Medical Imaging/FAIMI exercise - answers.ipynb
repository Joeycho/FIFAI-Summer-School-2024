{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84862c3e",
   "metadata": {},
   "source": [
    "## Professor Smith's Disease X theory\n",
    "\n",
    "Professor Smith is a researcher at Imaginary Hospital. She has noticed that some of her patients are contracting a mysterious disease. She has called the disease 'X' for now.\n",
    "\n",
    "She has collected data from some of her patients and used it as an input for an AI model that predicts whether the patient has the disease.\n",
    "\n",
    "First, let's load the data that she has collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%pip install openpyxl\n",
    "%pip install imbalanced-learn\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = pd.read_excel('subject_data_FIFAI.xlsx')\n",
    "print(patient_data)\n",
    "\n",
    "# # If reading excel failes, try:\n",
    "# patient_data = pd.read_csv('subject_data_FIFAI.csv')\n",
    "# print(patient_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b012a7",
   "metadata": {},
   "source": [
    "#### The spreadsheet contains the following data about the patients:\n",
    "\n",
    "- race (Black or White)\n",
    "- sex (Male or Female), \n",
    "- age (years)\n",
    "- Body Mass Index (BMI), \n",
    "- resting heart rate (HR)\n",
    "- the real or ground truth of whether the patient has Disease X (GT)\n",
    "- the prediction from an AI model\n",
    "\n",
    "For disease labels, 0 means the patient doesn't have the disease and 1 means they do have the disease.\n",
    "\n",
    "#### Let's calculate how accurate the predictions from the model are\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{TP + TN}{P + N} = \\frac{\\text{Number of correct predictions}}{\\text{Total}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb36699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is the number of correct predictions\n",
    "number_correct_predictions = len(np.where(patient_data.GT.values == patient_data.Predicted.values)[0])\n",
    "\n",
    "# Find the total number of patients\n",
    "total = len(patient_data)\n",
    "\n",
    "# Use the number of correct predictions and the total number of patients to find the accuracy\n",
    "accuracy = number_correct_predictions/ total\n",
    "\n",
    "print('The overall accuracy is {}%'.format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc43fae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>What do you think of the overall prediction accuracy?</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f89081",
   "metadata": {},
   "source": [
    "#### We can also calculate the overall sensitivity and specificity for the predictions using these equations:\n",
    "\n",
    "$$\n",
    "Sensitivity = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Specificity = \\frac{TN}{TN + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfb128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TP as an example, find the TN, FP and FN\n",
    "\n",
    "TP= len(np.where((patient_data.GT.values == 1) & (patient_data.Predicted.values==1))[0])\n",
    "TN= len(np.where((patient_data.GT.values == 0) & (patient_data.Predicted.values==0))[0])\n",
    "FP= len(np.where((patient_data.GT.values == 0) & (patient_data.Predicted.values==1))[0])\n",
    "FN= len(np.where((patient_data.GT.values == 1) & (patient_data.Predicted.values==0))[0])\n",
    "\n",
    "\n",
    "# Use the TP, FN, TN, and FP to find the sensitivity and specificity\n",
    "\n",
    "sensitivity = TP/(TP+FN)\n",
    "specificity = TN/(TN+FP)\n",
    "\n",
    "print('The overall sensitivity is {}%'.format(sensitivity*100))\n",
    "print('The overall specificity is {}%'.format(specificity*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542161f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>How do you interpret these results? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7929582",
   "metadata": {},
   "source": [
    "### Professor Smith has noticed that some of her patients catch the disease more frequently than others.\n",
    "\n",
    "Now let's work out what kinds of patients we have so we can investigate. Find the number of black, white, male and female patients in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_subjects_race = patient_data['Race'].value_counts()\n",
    "print(no_subjects_race)\n",
    "\n",
    "no_subjects_sex = patient_data['Sex'].value_counts()\n",
    "print(no_subjects_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c724799",
   "metadata": {},
   "source": [
    "#### Professor Smith thinks the difference in her patients getting the disease may be because some of her patients are healthier than others. \n",
    "\n",
    "The difference may be in the <span style='color:Blue'> male and female  </span>subjects. Let's calculate the accuracy for each of those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fbc227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the female subjects as an example, find the number of male subjects\n",
    "\n",
    "female_subjects = patient_data.where(patient_data['Sex']=='F').dropna()\n",
    "male_subjects = patient_data.where(patient_data['Sex']=='M').dropna()\n",
    "\n",
    "\n",
    "# This is very similar to the first question! Find the number of correct predictions (where the GT is equal to)\n",
    "# the predicted value\n",
    "correct_predictions_female = len(np.where(female_subjects.GT.values == female_subjects.Predicted.values)[0])\n",
    "\n",
    "accuracy = correct_predictions_female/ len(female_subjects)\n",
    "\n",
    "print('The accuracy for females is {:.1f}%'.format(accuracy*100))\n",
    "\n",
    "\n",
    "# Do the same for the male subjects\n",
    "correct_predictions_male = len(np.where(male_subjects.GT.values == male_subjects.Predicted.values)[0])\n",
    "\n",
    "accuracy = correct_predictions_male/ len(male_subjects)\n",
    "\n",
    "print('The accuracy for males is {:.1f}%'.format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75446314",
   "metadata": {},
   "source": [
    "\n",
    "#### The difference may instead be between <span style='color:Blue'> old and young </span> patients. Let's consider the patients over 50 the old patients and those below 50 the young patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the old and young subjects\n",
    "old_subjects = patient_data.where(patient_data['Age']>50).dropna()\n",
    "young_subjects = patient_data.where(patient_data['Age']<50).dropna()\n",
    "\n",
    "# Find the number of correct predictions for the old subjects\n",
    "correct_predictions_old = len(np.where(old_subjects.GT.values == old_subjects.Predicted.values)[0])\n",
    "\n",
    "accuracy = correct_predictions_old/ len(old_subjects)\n",
    "\n",
    "print('The accuracy for old subjects is {:.1f}%'.format(accuracy*100))\n",
    "\n",
    "\n",
    "# Find the number of correct predictions for the young subjects\n",
    "correct_predictions_young = len(np.where(young_subjects.GT.values == young_subjects.Predicted.values)[0])\n",
    "\n",
    "accuracy = correct_predictions_young/ len(young_subjects)\n",
    "\n",
    "print('The accuracy for young subjects is {:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c1d72d",
   "metadata": {},
   "source": [
    "\n",
    "#### The difference may instead be between the <span style='color:Blue'> Black and White  </span> subjects. Calculate the accuracy for those groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72941881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the black and white subjects\n",
    "black_subjects = patient_data.where(patient_data['Race']=='B').dropna()\n",
    "white_subjects = patient_data.where(patient_data['Race']=='W').dropna()\n",
    "\n",
    "# Find the number of correct predictions for the black subjects\n",
    "correct_predictions_black = len(np.where(black_subjects.GT.values == black_subjects.Predicted.values)[0])\n",
    "\n",
    "accuracy = correct_predictions_black/ len(black_subjects)\n",
    "\n",
    "print('The accuracy for black subjects is {:.1f}%'.format(accuracy*100))\n",
    "\n",
    "\n",
    "# Find the number of correct predictions for the white subjects\n",
    "correct_predictions_white = len(np.where(white_subjects.GT.values == white_subjects.Predicted.values)[0])\n",
    "\n",
    "accuracy = correct_predictions_white/ len(white_subjects)\n",
    "\n",
    "print('The accuracy for white subjects is {:.1f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89d6eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>How do you interpret these differences in accuracy for the groups? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057bf440",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What advice would you give to Professor X to improve the predictions? </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2449817",
   "metadata": {},
   "source": [
    "We can also calculate different <span style='color:green'> **fairness metrics** </span> for the subgroups. Below are the equations for different fairness metrics covered in the slides:\n",
    "\n",
    "1. Equal opportunity: equal change of positive classes being assigned positive predictions for each group\n",
    "$$\n",
    "Sensitivity = TPR = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "\n",
    "2. Equalised odds: equal true positive and false positive rates\n",
    "$$\n",
    "Sensitivity = TPR = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "$$\n",
    "FPR = 1 - Specificity = 1- \\frac{TN}{TN + FP}\n",
    "$$\n",
    "\n",
    "\n",
    "3. Demographic parity: equal change of positive predictions for each group\n",
    "$$\n",
    "PPR = \\frac{TP +FP}{TP + FP + TN + FN}\n",
    "$$\n",
    "\n",
    "Can you calculate and compare each of these metrics for the black and white subgroups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d36ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the TP, TN, FP and FN for each of the subgroups\n",
    "TP_black = len(np.where((black_subjects.GT.values == 1) & (black_subjects.Predicted.values==1))[0])\n",
    "TN_black = len(np.where((black_subjects.GT.values == 0) & (black_subjects.Predicted.values==0))[0])\n",
    "FP_black = len(np.where((black_subjects.GT.values == 0) & (black_subjects.Predicted.values==1))[0])\n",
    "FN_black = len(np.where((black_subjects.GT.values == 1) & (black_subjects.Predicted.values==0))[0])\n",
    "\n",
    "# Use the TP, TN, FP and FN to calculate the fairness metrics for the black subjects\n",
    "sensitivity_black = TP_black/(TP_black+FN_black)\n",
    "specificity_black = TN_black/(TN_black+FP_black)\n",
    "FPR_black = 1 - specificity_black\n",
    "PPR_black = (TP_black + FP_black)/(TP_black+FN_black+TN_black+FP_black)\n",
    "\n",
    "# Repeat for the white subjects\n",
    "TP_white = len(np.where((white_subjects.GT.values == 1) & (white_subjects.Predicted.values==1))[0])\n",
    "TN_white = len(np.where((white_subjects.GT.values == 0) & (white_subjects.Predicted.values==0))[0])\n",
    "FP_white = len(np.where((white_subjects.GT.values == 0) & (white_subjects.Predicted.values==1))[0])\n",
    "FN_white = len(np.where((white_subjects.GT.values == 1) & (white_subjects.Predicted.values==0))[0])\n",
    "\n",
    "# Use the TP, TN, FP and FN to calculate the fairness metrics for the white subjects\n",
    "sensitivity_white = TP_white /(TP_white +FN_white)\n",
    "specificity_white  = TN_white /(TN_white +FP_white )\n",
    "FPR_white  = 1 - specificity_white\n",
    "PPR_white  = (TP_white  + FP_white )/(TP_white +FN_white +TN_white +FP_white)\n",
    "\n",
    "print('Equal opportunity: Sensitivity for black subjects is {:.1f}% and {:.1f}% for white subjects'.format(sensitivity_black*100, sensitivity_white*100))\n",
    "print('Equal odds: FPR for black subjects is {:.1f}% and {:.1f}% for white subjects'.format(FPR_black*100, FPR_white*100))\n",
    "print('Demographic parity: PPR for black subjects is {:.1f}% and {:.1f}% for white subjects'.format(PPR_black*100, PPR_white*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd802153",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Bonus exercise: how healthy are the patients?</summary>\n",
    "\n",
    "### How healthy are these patients?\n",
    "\n",
    "It might be useful to find out whether the groups have different levels of health. Let's find the mean values of the BMI and HR for the black, white, male and female subjects.\n",
    "\n",
    "    The average BMI can be calculated using the Numpy mean function:\n",
    "```python\n",
    "average = np.mean(array)\n",
    "```\n",
    "\n",
    "Your code should look something like this:\n",
    "```python\n",
    "    \n",
    "BMI_black = np.mean(...)\n",
    "BMI_white = np.mean(...)\n",
    "BMI_female = np.mean(...)\n",
    "BMI_male = np.mean(...)\n",
    "\n",
    "print('The average BMI for black subjects is {}'.format(...)\n",
    "print('The average BMI for white subjects is {}'.format(...)\n",
    "print('The average BMI for male subjects is {}'.format(...)\n",
    "print('The average BMI for female subjects is {}'.format(...)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab696a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67c93a92",
   "metadata": {},
   "source": [
    "### Can we improve the model?\n",
    "\n",
    "Professor Smith wants to develop a more accurate method of diagnosing the disease. She wants to test another AI model to see whether it can predict if the patients have disease X. \n",
    "    \n",
    "Below is some code to run a model called a Ridge Classifier (you don't need to know the details but you can read about it [here](https://www.geeksforgeeks.org/ridge-classifier/) if you're interested). \n",
    "    \n",
    "First, let's split the data into training and testing set using [scikit-learn's train_test_split function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). You should split the data so that the proportion of Black and White subjects remains the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1de2bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(patient_data, patient_data['GT'], test_size=0.2, shuffle=True, stratify = patient_data['Race'])\n",
    "\n",
    "print('\\nTraining set:\\n {}'.format(X_train['Race'].value_counts()))\n",
    "print('\\nTest set\\n {}'.format(X_test['Race'].value_counts()))\n",
    "\n",
    "print('\\nThere are {} disease positive subjects and {} disease negative in the training set'.format(len(np.where(y_train == 1)[0]), len(np.where(y_train == 0)[0])))\n",
    "print('\\nThere are {} disease positive subjects and {} disease negative in the test set'.format(len(np.where(y_test == 1)[0]), len(np.where(y_test == 0)[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda679d3",
   "metadata": {},
   "source": [
    "####  Now let's train the model! We can use any scikit-learn classifer but let's start with the Ridge Classifier\n",
    "\n",
    "Make sure you have included all the measures of health (Age, BMI and HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54db7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model = RidgeClassifier(alpha=0.1).fit(X_train[['Age', 'HR', 'BMI']], y_train)\n",
    "\n",
    "#Make some predictions based on the test set\n",
    "predictions = model.predict(X_test[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions = len(np.where(y_test == predictions)[0])\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions/ len(X_test)\n",
    "\n",
    "print('The overall accuracy is {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b1072",
   "metadata": {},
   "source": [
    "#### Let's compare accuracy for Black and White subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6527ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the black and white subjects \n",
    "\n",
    "black_subjects = X_test.where(X_test['Race']=='B').dropna()\n",
    "white_subjects = X_test.where(X_test['Race']=='W').dropna()\n",
    "\n",
    "#Make some predictions based on the Black test data\n",
    "predictions_black = model.predict(black_subjects[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions_black = len(np.where(black_subjects['GT'] == predictions_black)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions_black/ len(black_subjects)\n",
    "\n",
    "print('The overall accuracy for Black subjects is {}%'.format(accuracy*100))\n",
    "\n",
    "#Make some predictions based on the White test data\n",
    "predictions_white = model.predict(white_subjects[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions_white  = len(np.where(white_subjects['GT'] == predictions_white )[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions_white / len(white_subjects)\n",
    "\n",
    "print('The overall accuracy for White subjects is {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f19306",
   "metadata": {},
   "source": [
    "####  We should also test the model on an external dataset. This will ensure that the model is not overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on external test set\n",
    "external_test = pd.read_excel('subject_data_external.xlsx')\n",
    "# external_test = pd.read_csv('subject_data_external.csv')\n",
    "\n",
    "#Make some predictions based on the patient data\n",
    "external_predictions = model.predict(external_test[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions = len(np.where(external_test['GT'] == external_predictions)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions/ len(external_test)\n",
    "\n",
    "print('The overall accuracy is {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0974c16",
   "metadata": {},
   "source": [
    "#### Let's compare accuracy for Black and White subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a094a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_subjects_external = external_test.where(external_test['Race']=='B').dropna()\n",
    "white_subjects_external = external_test.where(external_test['Race']=='W').dropna()\n",
    "\n",
    "#Make some predictions based on the patient data\n",
    "external_predictions_black = model.predict(black_subjects_external[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions_black = len(np.where(black_subjects_external['GT'] == external_predictions_black)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions_black/ len(black_subjects_external)\n",
    "\n",
    "print('The overall accuracy for Black subjects is {}%'.format(accuracy*100))\n",
    "\n",
    "#Make some predictions based on the patient data\n",
    "external_predictions_white = model.predict(white_subjects_external[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions_white  = len(np.where(white_subjects_external['GT'] == external_predictions_white)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions_white / len(white_subjects_external)\n",
    "\n",
    "print('The overall accuracy for White subjects is {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061a325",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>What do you think about the accuracy of the test set and external test set?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc81c7",
   "metadata": {},
   "source": [
    "####  Balancing the data\n",
    "\n",
    "Let's try and balance the number of positive and negative disease classes in the training dataset. We can do this by using the SMOTE method. We can use the `imblearn` package to do this\n",
    "\n",
    "You should balance the datasets by race, not disease label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1430d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Create an instance of SMOTE\n",
    "oversample = SMOTE()\n",
    "\n",
    "# Use the method to oversample the black subjects\n",
    "# HINT: you may need to use the .map() function from pandas to convert the race labels to integers\n",
    "X, y = oversample.fit_resample(patient_data.drop(columns=['Race', 'Sex']), patient_data['Race'].map({'W': 1, 'B': 0}) )\n",
    "\n",
    "counter = Counter(y)\n",
    "print(f'White subjects: {counter[0]} and Black subjects: {counter[1]}')\n",
    "\n",
    "# Split the data into training and testing sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['Age', 'HR', 'BMI']], X['GT'], test_size=0.2, shuffle=True, stratify = y)\n",
    "\n",
    "print('\\nThere are {} disease positive subjects and {} disease negative in the training set'.format(len(np.where(y_train == 1)[0]), len(np.where(y_train == 0)[0])))\n",
    "print('\\nThere are {} disease positive subjects and {} disease negative in the test set'.format(len(np.where(y_test == 1)[0]), len(np.where(y_test == 0)[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60ba1b",
   "metadata": {},
   "source": [
    "####  Let's retrain the model to see how balancing the proportions of races in the dataset has affected performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the model\n",
    "model = RidgeClassifier(alpha=0.1).fit(X_train, y_train)\n",
    "\n",
    "#Make some predictions based on original test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions = len(np.where(y_test == predictions)[0])\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions/ len(X_test)\n",
    "\n",
    "print('The overall accuracy is {}%'.format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b25d9",
   "metadata": {},
   "source": [
    "Test on the external test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Make some predictions based on the external dataset\n",
    "predictions = model.predict(external_test[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions = len(np.where(external_test['GT'] == predictions)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions/ len(external_test)\n",
    "\n",
    "print('The overall accuracy is {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477970f7",
   "metadata": {},
   "source": [
    "#### Let's compare accuracy for Black and White subjects for the external data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c293221",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_subjects_external = external_test.where(external_test['Race']=='B').dropna()\n",
    "white_subjects_external = external_test.where(external_test['Race']=='W').dropna()\n",
    "\n",
    "#Make some predictions based on the patient data\n",
    "predictions_black = model.predict(black_subjects_external[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions_black = len(np.where(black_subjects_external['GT'] == predictions_black)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions_black/ len(black_subjects_external)\n",
    "\n",
    "print('The overall accuracy for Black subjects is {}%'.format(accuracy*100))\n",
    "\n",
    "#Make some predictions based on the patient data\n",
    "predictions = model.predict(white_subjects_external[['Age', 'HR', 'BMI']])\n",
    "\n",
    "#Find the correct predictions\n",
    "correct_predictions = len(np.where(white_subjects_external['GT'] == predictions)[0])\n",
    "                                         \n",
    "#Calculate the accuracy\n",
    "accuracy = correct_predictions/ len(white_subjects_external)\n",
    "\n",
    "print('The overall accuracy for White subjects is {}%'.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
